{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2S-uFqwSvmg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUxLkBjISvmr"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xexp5GYNSvmz",
    "outputId": "48e3356f-3756-4945-f6b7-f643b59063b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54vJVc_KSvm9"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pKAn1-ASvm_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r97pFTgrSvnE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jykLIXZNSvnJ",
    "outputId": "2e462e5f-1546-4edf-bcc8-e7a42f9057d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0-M6oXASvnO"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sShoMeocSvnP"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm6wi8L2SvnU",
    "outputId": "dccc42b5-e1eb-4e2f-9fa2-07f405d4f761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4WFoxgASvnc",
    "outputId": "469de818-0a3e-42e8-bc19-ac6d088b9617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.13 seconds.\n",
      "Convergence after 10 epochs took 0.13 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WaVxhGpSvnj",
    "outputId": "1e67badc-96e7-4633-eb72-1d4c24aaa295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su9e8fRLSvno"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcz5_UqCSvnq"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOBvEchCSvnr"
   },
   "source": [
    "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xbn61rrXSvnt"
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14bA5yR3Svnv"
   },
   "source": [
    "- Load the datasets(train and test) into the respective arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7183hFBSvnv"
   },
   "source": [
    "- Initialize the weight_vector and intercept term randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdLeFU0USvnx"
   },
   "source": [
    "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEVtAlO1Svny"
   },
   "source": [
    "- for each epoch:\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
    "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
    "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
    "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qmRH4UpSvny"
   },
   "source": [
    "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbZf9p5gSvn1"
   },
   "source": [
    "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fpz8X5DMSvn2"
   },
   "outputs": [],
   "source": [
    "''' initalizing the default values '''\n",
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "eta0 = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(w), w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6Y5kVscSvn5"
   },
   "outputs": [],
   "source": [
    "# write your code to implement SGD as per the above instructions\n",
    "# please choose the number of iternations on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "''' Function for calculating loss'''\n",
    "def compute_log_loss(ground_truth ,model_predection):\n",
    "    # intitalising the variables, for calculating sum\n",
    "    total = 0\n",
    "    \n",
    "    for item in zip(ground_truth ,model_predection):\n",
    "        ''' Applying the formula '''\n",
    "#         print(item)\n",
    "        total += ( ( item[0]*math.log(item[1],10) ) + ((1.0-item[0])*math.log(1.0-item[1],10)) )\n",
    "    return (-1)*(1.0/len(ground_truth))*(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' sigmod function '''\n",
    "def sigmoid(w,X,b):\n",
    "#     print(w.shape, X.shape)\n",
    "    z = np.dot(X, w)+b\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model for predictions '''\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        predict.append(sigmoid(w, X[i], b))\n",
    "    return np.array(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current weight is\n",
      "[-0.2678707   0.12521946 -0.0449365   0.25699328 -0.02683356  0.38010378\n",
      " -0.39559008 -0.09734075  0.1358834   0.06412503  0.10842076  0.03008377\n",
      " -0.00996325  0.27432722  0.02323989]\n",
      "current bias is -0.31459274390122616\n",
      " training error is 0.17546926223702455 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 1/70 [00:02<02:54,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.17596687861916202 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.33449107  0.15763792 -0.08872853  0.30764261 -0.09240136  0.46954509\n",
      " -0.43846016 -0.10285442  0.16938704  0.10894921  0.14621215  0.02481835\n",
      " -0.03750694  0.3178868   0.01974299]\n",
      "current bias is -0.4709450275808126\n",
      " training error is 0.1686817443654028 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/70 [00:04<02:47,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16940989611779506 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.36809102  0.1715249  -0.1127206   0.32544734 -0.1346053   0.51100775\n",
      " -0.44609127 -0.10173028  0.18708703  0.13278339  0.16506264  0.01929227\n",
      " -0.05164829  0.33065519  0.01918252]\n",
      "current bias is -0.5798244820415148\n",
      " training error is 0.16639953379688424 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 3/70 [00:07<02:41,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.1672141530442443 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.38763204  0.17888717 -0.12620237  0.33270313 -0.16135369  0.53299782\n",
      " -0.44703842 -0.09943364  0.19773028  0.14644608  0.17589248  0.01467181\n",
      " -0.0603114   0.33524294  0.01949658]\n",
      "current bias is -0.659155130477768\n",
      " training error is 0.16537404901928238 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 4/70 [00:09<02:33,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16622329469756617 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.39996454  0.18327424 -0.13401962  0.33583383 -0.17880478  0.54557634\n",
      " -0.44670971 -0.09727012  0.20461796  0.15483246  0.18266666  0.01102903\n",
      " -0.0660834   0.33711584  0.0200539 ]\n",
      "current bias is -0.7177711262848345\n",
      " training error is 0.16486122004082648 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 5/70 [00:11<02:29,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16572403546384057 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.40819512  0.18608803 -0.13873193  0.33720386 -0.19058573  0.55321631\n",
      " -0.44625706 -0.09550674  0.20929646  0.16027648  0.18715532  0.00822064\n",
      " -0.0701101   0.33795986  0.0206259 ]\n",
      "current bias is -0.7613483856830057\n",
      " training error is 0.1645911450630783 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 6/70 [00:13<02:24,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16545876819806618 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.41391004  0.18798617 -0.14169517  0.33779395 -0.19878163  0.55810475\n",
      " -0.44590087 -0.09413778  0.21258307  0.16396875  0.19025299  0.00607829\n",
      " -0.0729975   0.33837632  0.02113129]\n",
      "current bias is -0.7938619893892721\n",
      " training error is 0.16444479874475684 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 7/70 [00:16<02:27,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.1653136522207702 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.41799064  0.18931327 -0.14363685  0.338036   -0.20462072  0.56137485\n",
      " -0.44565387 -0.09309556  0.21494694  0.16655711  0.19245324  0.00445306\n",
      " -0.07510418  0.33860217  0.02154898]\n",
      "current bias is -0.8181828420460676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 8/70 [00:18<02:21,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16436411522525887 for 37499 record in train dataset\n",
      " test error is 0.1652328356455146 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.42096142  0.190265   -0.14495661  0.33812517 -0.2088554   0.56364274\n",
      " -0.44549015 -0.09230872  0.21667522  0.16841596  0.19404807  0.00322381\n",
      " -0.07665874  0.33873738  0.0218821 ]\n",
      "current bias is -0.8364117186199179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 9/70 [00:20<02:19,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1643191231082832 for 37499 record in train dataset\n",
      " test error is 0.1651872786451104 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.42315311  0.19095979 -0.14588118  0.33814991 -0.21196623  0.56525978\n",
      " -0.44538357 -0.09171679  0.21795314  0.16977398  0.19522044  0.00229554\n",
      " -0.07781461  0.33882618  0.02214234]\n",
      "current bias is -0.8500967712837226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 10/70 [00:22<02:15,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642938291559788 for 37499 record in train dataset\n",
      " test error is 0.16516136116063082 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.42478454  0.19147327 -0.14654424  0.33814971 -0.21427234  0.56643631\n",
      " -0.44531465 -0.09127206  0.21890535  0.17077798  0.19609061  0.00159509\n",
      " -0.07867848  0.33888899  0.02234309]\n",
      "current bias is -0.860384347621053\n",
      " training error is 0.16427952013540809 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 11/70 [00:25<02:25,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.1651465026534052 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.42600612  0.19185592 -0.14702807  0.33814159 -0.21599274  0.56730455\n",
      " -0.44527011 -0.090938    0.21961854  0.17152628  0.19674069  0.0010667\n",
      " -0.07932641  0.33893568  0.02249674]\n",
      "current bias is -0.8681264033168422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 12/70 [00:27<02:18,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16427138331585123 for 37499 record in train dataset\n",
      " test error is 0.16513792321047302 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-0.42692436  0.19214267 -0.14738547  0.33813238 -0.2172818   0.56795146\n",
      " -0.44524125 -0.09068697  0.22015454  0.17208701  0.19722848  0.00066811\n",
      " -0.07981354  0.33897141  0.02261375]\n",
      "current bias is -0.8739580237448525\n",
      " training error is 0.16426673469647687 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 13/70 [00:30<02:18,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16513293346948316 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.27616303e-01  1.92358316e-01 -1.47651744e-01  3.38124448e-01\n",
      " -2.18250557e-01  5.68436504e-01 -4.45222439e-01 -9.04982276e-02\n",
      "  2.20558299e-01  1.72508692e-01  1.97595545e-01  3.67389682e-04\n",
      " -8.01804159e-02  3.38999148e-01  2.27025856e-02]\n",
      "current bias is -0.878353833823222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 14/70 [00:32<02:14,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642640668101494 for 37499 record in train dataset\n",
      " test error is 0.16513000875646822 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.28138526e-01  1.92520875e-01 -1.47851248e-01  3.38118324e-01\n",
      " -2.18980062e-01  5.68801644e-01 -4.45210076e-01 -9.03562109e-02\n",
      "  2.20862881e-01  1.72826524e-01  1.97872282e-01  1.40463403e-04\n",
      " -8.04570342e-02  3.39020779e-01  2.27698921e-02]\n",
      "current bias is -0.8816692980527855\n",
      " training error is 0.16426252835732985 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 15/70 [00:35<02:13,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512827929561433 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.28533036e-01  1.92643593e-01 -1.48001286e-01  3.38113848e-01\n",
      " -2.19530153e-01  5.69077199e-01 -4.45201873e-01 -9.02492808e-02\n",
      "  2.21092865e-01  1.73066429e-01  1.98081170e-01 -3.08167383e-05\n",
      " -8.06657705e-02  3.39037649e-01  2.28208263e-02]\n",
      "current bias is -0.8841711124069901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 16/70 [00:37<02:07,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426163646238537 for 37499 record in train dataset\n",
      " test error is 0.16512724616938715 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.28831233e-01  1.92736316e-01 -1.48114394e-01  3.38110676e-01\n",
      " -2.19945331e-01  5.69285453e-01 -4.45196367e-01 -9.01687170e-02\n",
      "  2.21266624e-01  1.73247674e-01  1.98238961e-01 -1.60125559e-04\n",
      " -8.08233708e-02  3.39050772e-01  2.28593424e-02]\n",
      "current bias is -0.8860596678436906\n",
      " training error is 0.16426111618838604 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 17/70 [00:40<02:09,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512662167682646 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29056700e-01  1.92806410e-01 -1.48199790e-01  3.38108466e-01\n",
      " -2.20258873e-01  5.69442969e-01 -4.45192628e-01 -9.01079832e-02\n",
      "  2.21397950e-01  1.73384672e-01  1.98358210e-01 -2.57768513e-04\n",
      " -8.09424082e-02  3.39060944e-01  2.28884558e-02]\n",
      "current bias is -0.8874857174993432\n",
      " training error is 0.1642608104485638 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 18/70 [00:43<02:21,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512623900834014 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29227202e-01  1.92859414e-01 -1.48264320e-01  3.38106939e-01\n",
      " -2.20495751e-01  5.69562156e-01 -4.45190055e-01 -9.00621757e-02\n",
      "  2.21497225e-01  1.73488254e-01  1.98448354e-01 -3.31513941e-04\n",
      " -8.10323422e-02  3.39068801e-01  2.29104570e-02]\n",
      "current bias is -0.8885627842328183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 19/70 [00:46<02:24,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642606291821092 for 37499 record in train dataset\n",
      " test error is 0.16512600086609056 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29356145e-01  1.92899498e-01 -1.48313108e-01  3.38105887e-01\n",
      " -2.20674756e-01  5.69652354e-01 -4.45188264e-01 -9.00276114e-02\n",
      "  2.21572280e-01  1.73566584e-01  1.98516506e-01 -3.87219641e-04\n",
      " -8.11003006e-02  3.39074847e-01  2.29270817e-02]\n",
      "current bias is -0.8893764233134068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 20/70 [00:48<02:09,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426052056735924 for 37499 record in train dataset\n",
      " test error is 0.16512585010563702 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29453659e-01  1.92929814e-01 -1.48350004e-01  3.38105161e-01\n",
      " -2.20810049e-01  5.69720614e-01 -4.45187001e-01 -9.00015216e-02\n",
      "  2.21629026e-01  1.73625819e-01  1.98568036e-01 -4.29304289e-04\n",
      " -8.11516596e-02  3.39079485e-01  2.29396434e-02]\n",
      "current bias is -0.8899911538531141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 21/70 [00:50<01:58,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642604546634997 for 37499 record in train dataset\n",
      " test error is 0.16512575289221296 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29527403e-01  1.92952741e-01 -1.48377910e-01  3.38104657e-01\n",
      " -2.20912313e-01  5.69772268e-01 -4.45186101e-01 -8.99818228e-02\n",
      "  2.21671931e-01  1.73670615e-01  1.98606998e-01 -4.61102109e-04\n",
      " -8.11904768e-02  3.39083034e-01  2.29491352e-02]\n",
      "current bias is -0.8904556560178001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 22/70 [00:52<01:49,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426041408844078 for 37499 record in train dataset\n",
      " test error is 0.1651256889988201 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29583167e-01  1.92970079e-01 -1.48399017e-01  3.38104306e-01\n",
      " -2.20989617e-01  5.69811351e-01 -4.45185453e-01 -8.99669458e-02\n",
      "  2.21704370e-01  1.73704490e-01  1.98636457e-01 -4.85129786e-04\n",
      " -8.12198167e-02  3.39085743e-01  2.29563076e-02]\n",
      "current bias is -0.8908066742845895\n",
      " training error is 0.16426038869248608 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 23/70 [00:54<01:44,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512564619491912 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29625335e-01  1.92983191e-01 -1.48414981e-01  3.38104059e-01\n",
      " -2.21048054e-01  5.69840919e-01 -4.45184982e-01 -8.99557082e-02\n",
      "  2.21728896e-01  1.73730106e-01  1.98658731e-01 -5.03287430e-04\n",
      " -8.12419940e-02  3.39087807e-01  2.29617276e-02]\n",
      "current bias is -0.8910719528105682\n",
      " training error is 0.16426037250710632 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 24/70 [00:56<01:38,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.1651256169861396 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29657219e-01  1.92993106e-01 -1.48427055e-01  3.38103883e-01\n",
      " -2.21092230e-01  5.69863286e-01 -4.45184638e-01 -8.99472184e-02\n",
      "  2.21747438e-01  1.73749475e-01  1.98675572e-01 -5.17009955e-04\n",
      " -8.12587576e-02  3.39089377e-01  2.29658236e-02]\n",
      "current bias is -0.8912724453007421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 25/70 [00:58<01:34,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426036199220245 for 37499 record in train dataset\n",
      " test error is 0.16512559670985227 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29681326e-01  1.93000603e-01 -1.48436186e-01  3.38103758e-01\n",
      " -2.21125625e-01  5.69880203e-01 -4.45184384e-01 -8.99408037e-02\n",
      "  2.21761457e-01  1.73764121e-01  1.98688304e-01 -5.27381181e-04\n",
      " -8.12714293e-02  3.39090570e-01  2.29689190e-02]\n",
      "current bias is -0.8914239801297006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 26/70 [01:00<01:30,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426035502610167 for 37499 record in train dataset\n",
      " test error is 0.16512558241566175 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29699552e-01  1.93006271e-01 -1.48443090e-01  3.38103668e-01\n",
      " -2.21150870e-01  5.69892997e-01 -4.45184196e-01 -8.99359564e-02\n",
      "  2.21772055e-01  1.73775194e-01  1.98697930e-01 -5.35219870e-04\n",
      " -8.12810080e-02  3.39091475e-01  2.29712585e-02]\n",
      "current bias is -0.89153851586812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 27/70 [01:02<01:29,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426035032139968 for 37499 record in train dataset\n",
      " test error is 0.16512557220222532 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29713332e-01  1.93010557e-01 -1.48448311e-01  3.38103602e-01\n",
      " -2.21169954e-01  5.69902673e-01 -4.45184056e-01 -8.99322933e-02\n",
      "  2.21780067e-01  1.73783566e-01  1.98705208e-01 -5.41144624e-04\n",
      " -8.12882487e-02  3.39092162e-01  2.29730267e-02]\n",
      "current bias is -0.8916250884879592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 28/70 [01:04<01:29,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426034708556325 for 37499 record in train dataset\n",
      " test error is 0.1651255648207193 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29723750e-01  1.93013797e-01 -1.48452259e-01  3.38103554e-01\n",
      " -2.21184381e-01  5.69909988e-01 -4.45183952e-01 -8.99295249e-02\n",
      "  2.21786124e-01  1.73789895e-01  1.98710710e-01 -5.45622872e-04\n",
      " -8.12937221e-02  3.39092682e-01  2.29743631e-02]\n",
      "current bias is -0.8916905262714768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 29/70 [01:07<01:30,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426034482265447 for 37499 record in train dataset\n",
      " test error is 0.16512555943510038 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29731626e-01  1.93016247e-01 -1.48455244e-01  3.38103518e-01\n",
      " -2.21195287e-01  5.69915520e-01 -4.45183874e-01 -8.99274325e-02\n",
      "  2.21790703e-01  1.73794680e-01  1.98714869e-01 -5.49007838e-04\n",
      " -8.12978595e-02  3.39093076e-01  2.29753732e-02]\n",
      "current bias is -0.8917399895774835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 30/70 [01:09<01:26,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426034321669825 for 37499 record in train dataset\n",
      " test error is 0.16512555547524244 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29737580e-01  1.93018098e-01 -1.48457500e-01  3.38103492e-01\n",
      " -2.21203531e-01  5.69919703e-01 -4.45183816e-01 -8.99258511e-02\n",
      "  2.21794165e-01  1.73798298e-01  1.98718013e-01 -5.51566466e-04\n",
      " -8.13009871e-02  3.39093374e-01  2.29761367e-02]\n",
      "current bias is -0.8917773784815544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 31/70 [01:11<01:23,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426034206250428 for 37499 record in train dataset\n",
      " test error is 0.16512555254561762 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29742081e-01  1.93019498e-01 -1.48459207e-01  3.38103473e-01\n",
      " -2.21209763e-01  5.69922865e-01 -4.45183772e-01 -8.99246557e-02\n",
      "  2.21796782e-01  1.73801032e-01  1.98720390e-01 -5.53500505e-04\n",
      " -8.13033513e-02  3.39093600e-01  2.29767138e-02]\n",
      "current bias is -0.8918056406971244\n",
      " training error is 0.1642603412241775 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 32/70 [01:13<01:22,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512555036754306 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29745483e-01  1.93020557e-01 -1.48460496e-01  3.38103458e-01\n",
      " -2.21214474e-01  5.69925255e-01 -4.45183739e-01 -8.99237522e-02\n",
      "  2.21798760e-01  1.73803100e-01  1.98722187e-01 -5.54962439e-04\n",
      " -8.13051385e-02  3.39093771e-01  2.29771501e-02]\n",
      "current bias is -0.8918270042091911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 33/70 [01:16<01:21,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426034060998645 for 37499 record in train dataset\n",
      " test error is 0.1651255487419859 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29748056e-01  1.93021357e-01 -1.48461471e-01  3.38103447e-01\n",
      " -2.21218036e-01  5.69927062e-01 -4.45183714e-01 -8.99230693e-02\n",
      "  2.21800255e-01  1.73804662e-01  1.98723545e-01 -5.56067516e-04\n",
      " -8.13064895e-02  3.39093900e-01  2.29774798e-02]\n",
      "current bias is -0.8918431530510396\n",
      " training error is 0.16426034015685897 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 34/70 [01:18<01:18,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554752515837 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29750000e-01  1.93021962e-01 -1.48462209e-01  3.38103439e-01\n",
      " -2.21220728e-01  5.69928429e-01 -4.45183695e-01 -8.99225531e-02\n",
      "  2.21801385e-01  1.73805844e-01  1.98724572e-01 -5.56902851e-04\n",
      " -8.13075107e-02  3.39093997e-01  2.29777290e-02]\n",
      "current bias is -0.8918553601331323\n",
      " training error is 0.16426033982070104 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 35/70 [01:20<01:16,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.1651255466121836 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29751470e-01  1.93022419e-01 -1.48462766e-01  3.38103433e-01\n",
      " -2.21222763e-01  5.69929461e-01 -4.45183681e-01 -8.99221629e-02\n",
      "  2.21802240e-01  1.73806737e-01  1.98725348e-01 -5.57534289e-04\n",
      " -8.13082826e-02  3.39094071e-01  2.29779174e-02]\n",
      "current bias is -0.8918645876254531\n",
      " training error is 0.16426033957023356 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 36/70 [01:22<01:16,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554592596942 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29752581e-01  1.93022764e-01 -1.48463187e-01  3.38103429e-01\n",
      " -2.21224301e-01  5.69930242e-01 -4.45183670e-01 -8.99218679e-02\n",
      "  2.21802886e-01  1.73807412e-01  1.98725935e-01 -5.58011600e-04\n",
      " -8.13088662e-02  3.39094127e-01  2.29780599e-02]\n",
      "current bias is -0.8918715628235859\n",
      " training error is 0.16426033938297835 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 37/70 [01:25<01:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554540949104 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29753421e-01  1.93023026e-01 -1.48463506e-01  3.38103425e-01\n",
      " -2.21225464e-01  5.69930832e-01 -4.45183662e-01 -8.99216449e-02\n",
      "  2.21803374e-01  1.73807922e-01  1.98726378e-01 -5.58372407e-04\n",
      " -8.13093073e-02  3.39094169e-01  2.29781675e-02]\n",
      "current bias is -0.8918768354887339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 38/70 [01:27<01:15,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642603392426212 for 37499 record in train dataset\n",
      " test error is 0.16512554502035892 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29754056e-01  1.93023223e-01 -1.48463746e-01  3.38103423e-01\n",
      " -2.21226343e-01  5.69931279e-01 -4.45183656e-01 -8.99214764e-02\n",
      "  2.21803743e-01  1.73808308e-01  1.98726713e-01 -5.58645146e-04\n",
      " -8.13096408e-02  3.39094201e-01  2.29782489e-02]\n",
      "current bias is -0.8918808211871662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 39/70 [01:29<01:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033913719873 for 37499 record in train dataset\n",
      " test error is 0.16512554472694171 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29754536e-01  1.93023373e-01 -1.48463928e-01  3.38103421e-01\n",
      " -2.21227007e-01  5.69931616e-01 -4.45183651e-01 -8.99213490e-02\n",
      "  2.21804022e-01  1.73808600e-01  1.98726967e-01 -5.58851314e-04\n",
      " -8.13098928e-02  3.39094225e-01  2.29783104e-02]\n",
      "current bias is -0.8918838340484826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 40/70 [01:31<01:06,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033905789575 for 37499 record in train dataset\n",
      " test error is 0.1651255445055628 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29754899e-01  1.93023485e-01 -1.48464066e-01  3.38103419e-01\n",
      " -2.21227510e-01  5.69931871e-01 -4.45183648e-01 -8.99212527e-02\n",
      "  2.21804233e-01  1.73808820e-01  1.98727158e-01 -5.59007160e-04\n",
      " -8.13100833e-02  3.39094244e-01  2.29783569e-02]\n",
      "current bias is -0.8918861115265115\n",
      " training error is 0.16426033899817313 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 41/70 [01:34<01:06,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554433845952 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755173e-01  1.93023571e-01 -1.48464170e-01  3.38103418e-01\n",
      " -2.21227889e-01  5.69932064e-01 -4.45183645e-01 -8.99211799e-02\n",
      "  2.21804393e-01  1.73808987e-01  1.98727303e-01 -5.59124966e-04\n",
      " -8.13102274e-02  3.39094258e-01  2.29783921e-02]\n",
      "current bias is -0.8918878331156846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 42/70 [01:36<01:04,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033895315278 for 37499 record in train dataset\n",
      " test error is 0.16512554421227899 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755380e-01  1.93023635e-01 -1.48464248e-01  3.38103417e-01\n",
      " -2.21228176e-01  5.69932209e-01 -4.45183643e-01 -8.99211249e-02\n",
      "  2.21804513e-01  1.73809113e-01  1.98727413e-01 -5.59214019e-04\n",
      " -8.13103363e-02  3.39094268e-01  2.29784186e-02]\n",
      "current bias is -0.8918891344984582\n",
      " training error is 0.16426033891919253 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 43/70 [01:38<01:02,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554411697636 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755537e-01  1.93023684e-01 -1.48464308e-01  3.38103416e-01\n",
      " -2.21228393e-01  5.69932319e-01 -4.45183642e-01 -8.99210833e-02\n",
      "  2.21804604e-01  1.73809208e-01  1.98727496e-01 -5.59281335e-04\n",
      " -8.13104186e-02  3.39094276e-01  2.29784387e-02]\n",
      "current bias is -0.8918901182393744\n",
      " training error is 0.16426033889356528 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 44/70 [01:41<01:01,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554404498 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755655e-01  1.93023721e-01 -1.48464353e-01  3.38103416e-01\n",
      " -2.21228557e-01  5.69932403e-01 -4.45183641e-01 -8.99210518e-02\n",
      "  2.21804673e-01  1.73809280e-01  1.98727558e-01 -5.59332221e-04\n",
      " -8.13104808e-02  3.39094282e-01  2.29784539e-02]\n",
      "current bias is -0.8918908618687542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 45/70 [01:43<00:59,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033887421454 for 37499 record in train dataset\n",
      " test error is 0.16512554399058307 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755745e-01  1.93023749e-01 -1.48464387e-01  3.38103416e-01\n",
      " -2.21228681e-01  5.69932466e-01 -4.45183640e-01 -8.99210281e-02\n",
      "  2.21804725e-01  1.73809335e-01  1.98727605e-01 -5.59370687e-04\n",
      " -8.13105278e-02  3.39094286e-01  2.29784654e-02]\n",
      "current bias is -0.8918914239931517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 46/70 [01:46<00:58,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642603388596005 for 37499 record in train dataset\n",
      " test error is 0.16512554394947776 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755813e-01  1.93023770e-01 -1.48464412e-01  3.38103415e-01\n",
      " -2.21228775e-01  5.69932513e-01 -4.45183639e-01 -8.99210101e-02\n",
      "  2.21804765e-01  1.73809376e-01  1.98727641e-01 -5.59399764e-04\n",
      " -8.13105633e-02  3.39094290e-01  2.29784740e-02]\n",
      "current bias is -0.8918918489143556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 47/70 [01:48<00:54,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033884856125 for 37499 record in train dataset\n",
      " test error is 0.16512554391841355 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755864e-01  1.93023786e-01 -1.48464432e-01  3.38103415e-01\n",
      " -2.21228846e-01  5.69932549e-01 -4.45183639e-01 -8.99209965e-02\n",
      "  2.21804794e-01  1.73809407e-01  1.98727668e-01 -5.59421743e-04\n",
      " -8.13105902e-02  3.39094292e-01  2.29784806e-02]\n",
      "current bias is -0.8918921701209147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 48/70 [01:50<00:48,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033884022054 for 37499 record in train dataset\n",
      " test error is 0.16512554389493533 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755903e-01  1.93023798e-01 -1.48464446e-01  3.38103415e-01\n",
      " -2.21228900e-01  5.69932576e-01 -4.45183638e-01 -8.99209862e-02\n",
      "  2.21804817e-01  1.73809430e-01  1.98727689e-01 -5.59438358e-04\n",
      " -8.13106105e-02  3.39094294e-01  2.29784856e-02]\n",
      "current bias is -0.8918924129275009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 49/70 [01:52<00:44,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033883392077 for 37499 record in train dataset\n",
      " test error is 0.16512554387719164 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755932e-01  1.93023807e-01 -1.48464457e-01  3.38103415e-01\n",
      " -2.21228940e-01  5.69932597e-01 -4.45183638e-01 -8.99209785e-02\n",
      "  2.21804834e-01  1.73809448e-01  1.98727704e-01 -5.59450918e-04\n",
      " -8.13106259e-02  3.39094296e-01  2.29784893e-02]\n",
      "current bias is -0.8918925964699665\n",
      " training error is 0.16426033882915658 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 50/70 [01:54<00:41,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554386378106 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755954e-01  1.93023814e-01 -1.48464466e-01  3.38103415e-01\n",
      " -2.21228971e-01  5.69932612e-01 -4.45183638e-01 -8.99209726e-02\n",
      "  2.21804847e-01  1.73809461e-01  1.98727716e-01 -5.59460412e-04\n",
      " -8.13106375e-02  3.39094297e-01  2.29784921e-02]\n",
      "current bias is -0.8918927352134758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 51/70 [01:56<00:38,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642603388255578 for 37499 record in train dataset\n",
      " test error is 0.16512554385364336 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755971e-01  1.93023819e-01 -1.48464472e-01  3.38103415e-01\n",
      " -2.21228994e-01  5.69932624e-01 -4.45183638e-01 -8.99209682e-02\n",
      "  2.21804856e-01  1.73809472e-01  1.98727724e-01 -5.59467589e-04\n",
      " -8.13106463e-02  3.39094298e-01  2.29784943e-02]\n",
      "current bias is -0.8918928400925312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 52/70 [01:58<00:35,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033882283855 for 37499 record in train dataset\n",
      " test error is 0.16512554384598138 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755983e-01  1.93023823e-01 -1.48464477e-01  3.38103415e-01\n",
      " -2.21229011e-01  5.69932633e-01 -4.45183637e-01 -8.99209648e-02\n",
      "  2.21804864e-01  1.73809479e-01  1.98727731e-01 -5.59473014e-04\n",
      " -8.13106529e-02  3.39094298e-01  2.29784959e-02]\n",
      "current bias is -0.891892919372772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 53/70 [02:00<00:33,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642603388207819 for 37499 record in train dataset\n",
      " test error is 0.1651255438401887 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29755993e-01  1.93023826e-01 -1.48464481e-01  3.38103415e-01\n",
      " -2.21229024e-01  5.69932640e-01 -4.45183637e-01 -8.99209623e-02\n",
      "  2.21804869e-01  1.73809485e-01  1.98727736e-01 -5.59477115e-04\n",
      " -8.13106579e-02  3.39094299e-01  2.29784971e-02]\n",
      "current bias is -0.8918929793023364\n",
      " training error is 0.16426033881922866 for 37499 record in train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 54/70 [02:01<00:31,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test error is 0.16512554383581135 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756000e-01  1.93023828e-01 -1.48464483e-01  3.38103415e-01\n",
      " -2.21229034e-01  5.69932645e-01 -4.45183637e-01 -8.99209604e-02\n",
      "  2.21804873e-01  1.73809489e-01  1.98727740e-01 -5.59480215e-04\n",
      " -8.13106617e-02  3.39094299e-01  2.29784981e-02]\n",
      "current bias is -0.8918930246043207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 55/70 [02:03<00:28,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881805266 for 37499 record in train dataset\n",
      " test error is 0.16512554383250266 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756005e-01  1.93023830e-01 -1.48464485e-01  3.38103415e-01\n",
      " -2.21229042e-01  5.69932649e-01 -4.45183637e-01 -8.99209589e-02\n",
      "  2.21804877e-01  1.73809493e-01  1.98727743e-01 -5.59482558e-04\n",
      " -8.13106646e-02  3.39094299e-01  2.29784988e-02]\n",
      "current bias is -0.8918930588490338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 56/70 [02:05<00:26,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881716615 for 37499 record in train dataset\n",
      " test error is 0.1651255438300008 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756010e-01  1.93023831e-01 -1.48464487e-01  3.38103415e-01\n",
      " -2.21229048e-01  5.69932652e-01 -4.45183637e-01 -8.99209578e-02\n",
      "  2.21804879e-01  1.73809495e-01  1.98727745e-01 -5.59484329e-04\n",
      " -8.13106667e-02  3.39094300e-01  2.29784993e-02]\n",
      "current bias is -0.8918930847353151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 57/70 [02:07<00:24,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642603388164946 for 37499 record in train dataset\n",
      " test error is 0.16512554382810932 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756013e-01  1.93023832e-01 -1.48464488e-01  3.38103415e-01\n",
      " -2.21229052e-01  5.69932654e-01 -4.45183637e-01 -8.99209570e-02\n",
      "  2.21804881e-01  1.73809497e-01  1.98727747e-01 -5.59485668e-04\n",
      " -8.13106684e-02  3.39094300e-01  2.29784997e-02]\n",
      "current bias is -0.891893104303281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 58/70 [02:09<00:22,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881598764 for 37499 record in train dataset\n",
      " test error is 0.16512554382668013 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756015e-01  1.93023833e-01 -1.48464489e-01  3.38103415e-01\n",
      " -2.21229055e-01  5.69932655e-01 -4.45183637e-01 -8.99209564e-02\n",
      "  2.21804882e-01  1.73809499e-01  1.98727748e-01 -5.59486681e-04\n",
      " -8.13106696e-02  3.39094300e-01  2.29785000e-02]\n",
      "current bias is -0.891893119095114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 59/70 [02:11<00:20,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881560353 for 37499 record in train dataset\n",
      " test error is 0.16512554382560016 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756017e-01  1.93023833e-01 -1.48464490e-01  3.38103415e-01\n",
      " -2.21229058e-01  5.69932657e-01 -4.45183637e-01 -8.99209559e-02\n",
      "  2.21804883e-01  1.73809500e-01  1.98727749e-01 -5.59487446e-04\n",
      " -8.13106706e-02  3.39094300e-01  2.29785002e-02]\n",
      "current bias is -0.8918931302765681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 60/70 [02:12<00:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881531346 for 37499 record in train dataset\n",
      " test error is 0.16512554382478273 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756018e-01  1.93023834e-01 -1.48464490e-01  3.38103415e-01\n",
      " -2.21229060e-01  5.69932658e-01 -4.45183637e-01 -8.99209556e-02\n",
      "  2.21804884e-01  1.73809500e-01  1.98727750e-01 -5.59488024e-04\n",
      " -8.13106713e-02  3.39094300e-01  2.29785004e-02]\n",
      "current bias is -0.8918931387288516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 61/70 [02:14<00:16,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881509533 for 37499 record in train dataset\n",
      " test error is 0.16512554382416447 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756019e-01  1.93023834e-01 -1.48464491e-01  3.38103415e-01\n",
      " -2.21229061e-01  5.69932658e-01 -4.45183637e-01 -8.99209553e-02\n",
      "  2.21804885e-01  1.73809501e-01  1.98727750e-01 -5.59488461e-04\n",
      " -8.13106718e-02  3.39094300e-01  2.29785005e-02]\n",
      "current bias is -0.8918931451181027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 62/70 [02:16<00:15,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881492785 for 37499 record in train dataset\n",
      " test error is 0.16512554382369862 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756020e-01  1.93023834e-01 -1.48464491e-01  3.38103415e-01\n",
      " -2.21229062e-01  5.69932659e-01 -4.45183637e-01 -8.99209551e-02\n",
      "  2.21804885e-01  1.73809502e-01  1.98727751e-01 -5.59488792e-04\n",
      " -8.13106722e-02  3.39094300e-01  2.29785006e-02]\n",
      "current bias is -0.8918931499478842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 63/70 [02:18<00:13,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881480348 for 37499 record in train dataset\n",
      " test error is 0.16512554382334668 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756021e-01  1.93023834e-01 -1.48464491e-01  3.38103415e-01\n",
      " -2.21229063e-01  5.69932659e-01 -4.45183637e-01 -8.99209549e-02\n",
      "  2.21804885e-01  1.73809502e-01  1.98727751e-01 -5.59489042e-04\n",
      " -8.13106725e-02  3.39094300e-01  2.29785007e-02]\n",
      "current bias is -0.891893153598805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 64/70 [02:20<00:11,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881470875 for 37499 record in train dataset\n",
      " test error is 0.16512554382308 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756021e-01  1.93023834e-01 -1.48464491e-01  3.38103415e-01\n",
      " -2.21229064e-01  5.69932660e-01 -4.45183637e-01 -8.99209548e-02\n",
      "  2.21804886e-01  1.73809502e-01  1.98727751e-01 -5.59489231e-04\n",
      " -8.13106727e-02  3.39094300e-01  2.29785007e-02]\n",
      "current bias is -0.8918931563586091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 65/70 [02:22<00:09,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881463978 for 37499 record in train dataset\n",
      " test error is 0.16512554382287753 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756021e-01  1.93023835e-01 -1.48464491e-01  3.38103415e-01\n",
      " -2.21229064e-01  5.69932660e-01 -4.45183637e-01 -8.99209547e-02\n",
      "  2.21804886e-01  1.73809502e-01  1.98727751e-01 -5.59489373e-04\n",
      " -8.13106729e-02  3.39094300e-01  2.29785008e-02]\n",
      "current bias is -0.8918931584448103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 66/70 [02:24<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881458382 for 37499 record in train dataset\n",
      " test error is 0.16512554382272598 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756022e-01  1.93023835e-01 -1.48464492e-01  3.38103415e-01\n",
      " -2.21229064e-01  5.69932660e-01 -4.45183637e-01 -8.99209547e-02\n",
      "  2.21804886e-01  1.73809503e-01  1.98727751e-01 -5.59489481e-04\n",
      " -8.13106730e-02  3.39094300e-01  2.29785008e-02]\n",
      "current bias is -0.8918931600218077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 67/70 [02:26<00:05,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.1642603388145426 for 37499 record in train dataset\n",
      " test error is 0.16512554382260966 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756022e-01  1.93023835e-01 -1.48464492e-01  3.38103415e-01\n",
      " -2.21229065e-01  5.69932660e-01 -4.45183637e-01 -8.99209546e-02\n",
      "  2.21804886e-01  1.73809503e-01  1.98727752e-01 -5.59489563e-04\n",
      " -8.13106731e-02  3.39094300e-01  2.29785008e-02]\n",
      "current bias is -0.891893161213896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 68/70 [02:28<00:03,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881451096 for 37499 record in train dataset\n",
      " test error is 0.16512554382252367 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756022e-01  1.93023835e-01 -1.48464492e-01  3.38103415e-01\n",
      " -2.21229065e-01  5.69932660e-01 -4.45183637e-01 -8.99209546e-02\n",
      "  2.21804886e-01  1.73809503e-01  1.98727752e-01 -5.59489624e-04\n",
      " -8.13106732e-02  3.39094300e-01  2.29785009e-02]\n",
      "current bias is -0.8918931621150121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 69/70 [02:29<00:01,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881448804 for 37499 record in train dataset\n",
      " test error is 0.16512554382245748 for 37499 record in test dataset\n",
      "current weight is\n",
      "[-4.29756022e-01  1.93023835e-01 -1.48464492e-01  3.38103415e-01\n",
      " -2.21229065e-01  5.69932660e-01 -4.45183637e-01 -8.99209545e-02\n",
      "  2.21804886e-01  1.73809503e-01  1.98727752e-01 -5.59489671e-04\n",
      " -8.13106733e-02  3.39094300e-01  2.29785009e-02]\n",
      "current bias is -0.8918931627961899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:31<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training error is 0.16426033881447086 for 37499 record in train dataset\n",
      " test error is 0.16512554382240752 for 37499 record in test dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "'''  intintializing the values '''\n",
    "total_records = len(X_train)\n",
    "train_loss_list = []\n",
    "test_loss_list  = []\n",
    "reducing_weights = [w]\n",
    "reducing_bais    = [b]\n",
    "''' Looping through each epoch '''\n",
    "for each_point in tqdm(range(0, 70)):\n",
    "    ''' Iterating for each batch '''\n",
    "    for each_batch in range(0, total_records):\n",
    "        ''' Getting random index '''\n",
    "        get_random_input =each_batch\n",
    "        ''' calculating the error '''\n",
    "        error = y_train[get_random_input] - sigmoid(w.T,X_train[get_random_input],b)\n",
    "        ''' Update weight vector '''\n",
    "        w = (1- ((alpha*eta0)/total_records))*w + (alpha*X_train[get_random_input]*\n",
    "                                                   (error))\n",
    "        ''' update intercept'''\n",
    "        b = (b+ alpha*(y_train[get_random_input] - sigmoid(w.T,X_train[get_random_input],b)))\n",
    "    ''' stroing the optimized weigths and bais for each epoch'''\n",
    "    reducing_weights.append(w)\n",
    "    reducing_bais.append(b)\n",
    "    print('current weight is')\n",
    "    print(w)\n",
    "    print('current bias is {}'.format(b))\n",
    "    ''' calculate model predection on train data  '''\n",
    "    get_train_prediction = pred(w.T,b, X_train)\n",
    "    ''' calculate train loss '''\n",
    "    get_train_loss = compute_log_loss(y_train ,get_train_prediction)\n",
    "    train_loss_list.append(get_train_loss)\n",
    "    print(' training error is {} for {} record in train dataset'.format(get_train_loss,get_random_input))\n",
    "    ''' calculate model predection on test data  '''\n",
    "    get_train_prediction = pred(w.T,b, X_test)\n",
    "    ''' calculate test loss '''\n",
    "    get_train_loss = compute_log_loss(y_test ,get_train_prediction)\n",
    "    test_loss_list.append(get_train_loss)\n",
    "    print(' test error is {} for {} record in test dataset'.format(get_train_loss,get_random_input))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned from mistake's\n",
    "    - Do not use get_random_input =random.randrange(0, total_records) because model will not \n",
    "      learn from all point in  vanilla sgd\n",
    "    - To overcome it get_random_input = each_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.17546926223702455,\n",
       "  0.1686817443654028,\n",
       "  0.16639953379688424,\n",
       "  0.16537404901928238,\n",
       "  0.16486122004082648,\n",
       "  0.1645911450630783,\n",
       "  0.16444479874475684,\n",
       "  0.16436411522525887,\n",
       "  0.1643191231082832,\n",
       "  0.1642938291559788,\n",
       "  0.16427952013540809,\n",
       "  0.16427138331585123,\n",
       "  0.16426673469647687,\n",
       "  0.1642640668101494,\n",
       "  0.16426252835732985,\n",
       "  0.16426163646238537,\n",
       "  0.16426111618838604,\n",
       "  0.1642608104485638,\n",
       "  0.1642606291821092,\n",
       "  0.16426052056735924,\n",
       "  0.1642604546634997,\n",
       "  0.16426041408844078,\n",
       "  0.16426038869248608,\n",
       "  0.16426037250710632,\n",
       "  0.16426036199220245,\n",
       "  0.16426035502610167,\n",
       "  0.16426035032139968,\n",
       "  0.16426034708556325,\n",
       "  0.16426034482265447,\n",
       "  0.16426034321669825,\n",
       "  0.16426034206250428,\n",
       "  0.1642603412241775,\n",
       "  0.16426034060998645,\n",
       "  0.16426034015685897,\n",
       "  0.16426033982070104,\n",
       "  0.16426033957023356,\n",
       "  0.16426033938297835,\n",
       "  0.1642603392426212,\n",
       "  0.16426033913719873,\n",
       "  0.16426033905789575,\n",
       "  0.16426033899817313,\n",
       "  0.16426033895315278,\n",
       "  0.16426033891919253,\n",
       "  0.16426033889356528,\n",
       "  0.16426033887421454,\n",
       "  0.1642603388596005,\n",
       "  0.16426033884856125,\n",
       "  0.16426033884022054,\n",
       "  0.16426033883392077,\n",
       "  0.16426033882915658,\n",
       "  0.1642603388255578,\n",
       "  0.16426033882283855,\n",
       "  0.1642603388207819,\n",
       "  0.16426033881922866,\n",
       "  0.16426033881805266,\n",
       "  0.16426033881716615,\n",
       "  0.1642603388164946,\n",
       "  0.16426033881598764,\n",
       "  0.16426033881560353,\n",
       "  0.16426033881531346,\n",
       "  0.16426033881509533,\n",
       "  0.16426033881492785,\n",
       "  0.16426033881480348,\n",
       "  0.16426033881470875,\n",
       "  0.16426033881463978,\n",
       "  0.16426033881458382,\n",
       "  0.1642603388145426,\n",
       "  0.16426033881451096,\n",
       "  0.16426033881448804,\n",
       "  0.16426033881447086],\n",
       " [0.17596687861916202,\n",
       "  0.16940989611779506,\n",
       "  0.1672141530442443,\n",
       "  0.16622329469756617,\n",
       "  0.16572403546384057,\n",
       "  0.16545876819806618,\n",
       "  0.1653136522207702,\n",
       "  0.1652328356455146,\n",
       "  0.1651872786451104,\n",
       "  0.16516136116063082,\n",
       "  0.1651465026534052,\n",
       "  0.16513792321047302,\n",
       "  0.16513293346948316,\n",
       "  0.16513000875646822,\n",
       "  0.16512827929561433,\n",
       "  0.16512724616938715,\n",
       "  0.16512662167682646,\n",
       "  0.16512623900834014,\n",
       "  0.16512600086609056,\n",
       "  0.16512585010563702,\n",
       "  0.16512575289221296,\n",
       "  0.1651256889988201,\n",
       "  0.16512564619491912,\n",
       "  0.1651256169861396,\n",
       "  0.16512559670985227,\n",
       "  0.16512558241566175,\n",
       "  0.16512557220222532,\n",
       "  0.1651255648207193,\n",
       "  0.16512555943510038,\n",
       "  0.16512555547524244,\n",
       "  0.16512555254561762,\n",
       "  0.16512555036754306,\n",
       "  0.1651255487419859,\n",
       "  0.16512554752515837,\n",
       "  0.1651255466121836,\n",
       "  0.16512554592596942,\n",
       "  0.16512554540949104,\n",
       "  0.16512554502035892,\n",
       "  0.16512554472694171,\n",
       "  0.1651255445055628,\n",
       "  0.16512554433845952,\n",
       "  0.16512554421227899,\n",
       "  0.16512554411697636,\n",
       "  0.16512554404498,\n",
       "  0.16512554399058307,\n",
       "  0.16512554394947776,\n",
       "  0.16512554391841355,\n",
       "  0.16512554389493533,\n",
       "  0.16512554387719164,\n",
       "  0.16512554386378106,\n",
       "  0.16512554385364336,\n",
       "  0.16512554384598138,\n",
       "  0.1651255438401887,\n",
       "  0.16512554383581135,\n",
       "  0.16512554383250266,\n",
       "  0.1651255438300008,\n",
       "  0.16512554382810932,\n",
       "  0.16512554382668013,\n",
       "  0.16512554382560016,\n",
       "  0.16512554382478273,\n",
       "  0.16512554382416447,\n",
       "  0.16512554382369862,\n",
       "  0.16512554382334668,\n",
       "  0.16512554382308,\n",
       "  0.16512554382287753,\n",
       "  0.16512554382272598,\n",
       "  0.16512554382260966,\n",
       "  0.16512554382252367,\n",
       "  0.16512554382245748,\n",
       "  0.16512554382240752])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_list,test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.29756022e-01,  1.93023835e-01, -1.48464492e-01,  3.38103415e-01,\n",
       "        -2.21229065e-01,  5.69932660e-01, -4.45183637e-01, -8.99209545e-02,\n",
       "         2.21804886e-01,  1.73809503e-01,  1.98727752e-01, -5.59489671e-04,\n",
       "        -8.13106733e-02,  3.39094300e-01,  2.29785009e-02]),\n",
       " -0.8918931627961899)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Displaying the final weights & intecept '''\n",
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "GET_Weights_NUMPY = np.array(reducing_weights)\n",
    "''' Each feature weights are is updating '''\n",
    "for each_loop in range(GET_Weights_NUMPY.shape[0]):\n",
    "    plt.plot(GET_Weights_NUMPY[:,])\n",
    "    plt.xlabel('ecpocs')\n",
    "    plt.ylabel('weights value')\n",
    "plt.show()\n",
    "''' Intercept is updating '''\n",
    "plt.plot(reducing_bais)\n",
    "plt.xlabel('ecpocs')\n",
    "plt.ylabel('bais value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5RdZZ3m8e9T11MhJCGkMJEQUkgUY4sBK8ELRMGFRuwFXoIk2rSM0BkdWXS3zWBc46DDjO2FGbV1sAVv3bYI0solreHWmEHb1Q25EC5JDJQhhoKEREmAmGtV/eaPvU/VSaVy6pyq2nVO6jyfxVl19jW/U6uop9733Xu/igjMzMxKVVfpAszM7Oji4DAzs7I4OMzMrCwODjMzK4uDw8zMyuLgMDOzsmQaHJIWSNooqUPS0gG2z5e0RlKXpIUF68+VtLbgtU/Se9NtkvR5SU9K2iDpqiw/g5mZHaohqxNLqgduAM4HOoGVkpZFxPqC3bYAlwFXFx4bESuAOel5JgMdwH3p5suAk4DTIqJH0glZfQYzMztcZsEBzAM6ImITgKRbgYuA3uCIiM3ptp4i51kI3B0Re9LljwMfioie9BzbR750MzM7kiyD40TgmYLlTuCsIZxnEfCVguVXAZdIeh+wA7gqIp4qdoIpU6bEzJkzh/BPm5nVrtWrV/8+Ilr7r88yOIZN0jTg9cC9BaubgX0R0S7p/cD3gHMGOHYJsARgxowZrFq1ahQqNjMbOyT9bqD1WQ6OP0syFpE3PV1Xjg8Cd0TEwYJ1ncDt6fs7gNMHOjAiboqI9ohob209LDDNzGyIsgyOlcAsSW2Smki6nJaVeY7FwC391t0JnJu+fxvw5LCqNDOzsmQWHBHRBVxJ0s20AbgtItZJuk7ShQCS5krqBC4GbpS0Ln+8pJkkLZYH+536i8AHJD0OfAG4IqvPYGZmh1MtPFa9vb09PMZhZlYeSasjor3/et85bmZmZXFwmJlZWRwcZmZWFgdHEXc80skP/2PAy5jNzGqWg6OIf3l0K7c8vKXSZZiZVRUHRxEtjfXsO9hd6TLMzKqKg6OI5sY69h0s9vxFM7Pa4+Aowi0OM7PDOTiKyDk4zMwO4+AooqWxnr0Hu6mFu+vNzErl4Cgi11hHT8DBbgeHmVmeg6OIXGM9AHvdXWVm1svBUUQ+OPY7OMzMejk4isgHhy/JNTPr4+AoosVdVWZmh3FwFJFrTL49viTXzKyPg6MItzjMzA7n4CiiuXeMw8FhZpbn4CiixcFhZnYYB0cRfWMcvqrKzCzPwVFEzi0OM7PDODiK8OC4mdnhHBxF+AZAM7PDOTiKaG5Ivj1ucZiZ9XFwFFFXJ5ob6vysKjOzAg6OQbQ01bvFYWZWINPgkLRA0kZJHZKWDrB9vqQ1krokLSxYf66ktQWvfZLe2+/Yr0vanWX9ALkGzwJoZlaoIasTS6oHbgDOBzqBlZKWRcT6gt22AJcBVxceGxErgDnpeSYDHcB9BeduB47LqvZCucY69npw3MysV5YtjnlAR0RsiogDwK3ARYU7RMTmiHgMKPabeSFwd0Tsgd5Auh64JpuyD+V5x83MDpVlcJwIPFOw3JmuK9ci4JaC5SuBZRGxdRi1lczBYWZ2qMy6qkaCpGnA64F70+VXAhcDby/h2CXAEoAZM2YMuYYWB4eZ2SGybHE8C5xUsDw9XVeODwJ3RMTBdPkM4FSgQ9JmYJykjoEOjIibIqI9ItpbW1vL/Gf75BrrfAOgmVmBLFscK4FZktpIAmMR8KEyz7EY+HR+ISJ+DkzNL0vaHRGnjkCtR+TLcc3MDpVZiyMiukjGI+4FNgC3RcQ6SddJuhBA0lxJnSTdTzdKWpc/XtJMkhbLg1nVWApfjmtmdqhMxzgiYjmwvN+6awveryTpwhro2M0MMpgeEeOHX2VxuSYHh5lZId85PoikxeExDjOzPAfHIJLBcbc4zMzyHByDaGmsp6snONjtVoeZGTg4BuVZAM3MDuXgGESuybMAmpkVcnAMIpdO5rTfA+RmZoCDY1AtbnGYmR3CwTGIXIPHOMzMCjk4BtE3OO6uKjMzcHAMqqUp+Ra5q8rMLOHgGESzu6rMzA7h4BhEfnDcwWFmlnBwDMI3AJqZHcrBMYiWNDj2HnBwmJmBg2NQucbkW7Svy1dVmZmBg2NQvo/DzOxQDo5B1NWJpoY6X45rZpZycJQg11DnZ1WZmaUcHCVoaar34LiZWcrBUYJcYz37uhwcZmbg4ChJS6NbHGZmeQ6OEjQ31vtyXDOzlIOjBC2Ndexzi8PMDHBwlMRjHGZmfRwcJcg11PsGQDOzlIOjBC1N9b4B0Mws5eAoQa6xzjMAmpmlMg0OSQskbZTUIWnpANvnS1ojqUvSwoL150paW/DaJ+m96bab03M+Iel7khqz/AyQjnF4cNzMDMgwOCTVAzcA7wZmA4slze632xbgMuBHhSsjYkVEzImIOcB5wB7gvnTzzcBpwOuBFuCKrD5DngfHzcz6NGR47nlAR0RsApB0K3ARsD6/Q0RsTrcV6wdaCNwdEXvSY5bnN0h6GJg+4pX309JYz8HuoKu7h4Z69+6ZWW3L8rfgicAzBcud6bpyLQJu6b8y7aK6FLhnoIMkLZG0StKqHTt2DOGf7eM5OczM+lT1n8+SppF0Sd07wOZvAr+MiF8NdGxE3BQR7RHR3traOqw6Wjx9rJlZryy7qp4FTipYnp6uK8cHgTsi4mDhSkmfBVqB/zysCkvU7Oljzcx6ZdniWAnMktQmqYmky2lZmedYTL9uKklXAO8CFkfEqPQd5dLg2O8BcjOz7IIjIrqAK0m6mTYAt0XEOknXSboQQNJcSZ3AxcCNktblj5c0k6TF8mC/U38LeAXw7+mlutdm9RnyWnpbHB7jMDPLsqsqfwXU8n7rri14v5IjXBWVXnF12GB6RGRa80D6Bsfd4jAzq+rB8WrR4jEOM7NegwaHpPdLOjZ9v1TSbZLmZF9a9cj5qiozs16ltDg+FxEvS3oLcAHJndvfyras6tIbHL6Pw8yspODI/5n9p8CNEXEX0JxdSdWnd4zDXVVmZiUNjm+VdAOwAGhPL62tqbGRvhaHg8PMrJQA+CDJJbHviYidwBTgsCfdjmUeHDcz61NKi2MKcFdE7Jd0NnA68MNsy6oufYPjHuMwMyulxXEn0CPpVcD3gVn0ewz6WFdfJ5rq6zwLoJkZpQVHT/qsqPcD34iIv2ZoT7k9qjU31vlyXDMzSguOLkkXkzzC/Gfpusxn3as2LY31flaVmRmlBcdHgXOBL0fEJkltDDA/xliXa6z34LiZGSUMjkfEE5KuAk6VdBrJrH6fz7606tLSWO/BcTMzSggOSecA/0Qyl4aAqZIujYhfZ11cNck1enDczAxKuxz3q8AFEbEeQNJrSYKkPcvCqk1zY70Hx83MKG2MoykfGgARsQFoyq6k6tTi4DAzA0prcayR9C36bvr7MPBIdiVVp1xjncc4zMwoLTg+BlwFXJMu/wr4emYVVamWxnqPcZiZUdpVVfuAL6cvACTdTNLyqBk5d1WZmQFDf8rtOSNaxVHAwWFmlqipx6MPR873cZiZAUW6qiSdfqRN1OAjR3KNdRzo7qG7J6ivU6XLMTOrmGJjHDcU2dYx0oVUu5aCecePaS7lmgIzs7HpiL8BI6LmxjGKyTk4zMwAj3GUrHcWQA+Qm1mNc3CUqLkx+VZ5gNzMap2Do0SFYxxmZrVs0OCQdPoAr5MllXLsAkkbJXVIWjrA9vmS1kjqkrSwYP25ktYWvPZJem+6rU3SQ+k5fyxpVJ6blXNwmJkBpbU4vgusBn5A8lTcVcBdwFOS3nGkgyTVk1yZ9W5gNrBY0ux+u20BLqPfHOYRsSIi5kTEHOA8YA9wX7r5S8BXI+JUYCdweQmfYdhamvLB4a4qM6ttpQTHZuCN6S/yNwBvBJ4E3gX8nyLHzSOZ9GlTRBwAbgUuKtwhIjZHxGNAsd/GC4G7I2KPJJEEyU/Sbf8IvLeEzzBsuQYPjpuZQWnB8dr0lzsAEfE4MDsiBruX40TgmYLlznRduRbRN1Xt8cCuiOga5jnLlusdHHdwmFltK+WGhN9I+gZJiwHgknRdM9B15MOGT9I04PXAvUM4dgmwBGDGjBnDriXny3HNzIDSWhx/TvKX/dL09RzwEZLQOOIYB8lUsycVLE9P15Xjg8AdEXEwXf4DMElSPvCOeM6IuCki2iOivbW1tcx/9nD54Njv4DCzGlfKY9X3kAxIf2mAzS8WOXQlMEtSG8kv90XAh8qsbzHw6YJaQtIKknGPW0kC7K4yzzkkHhw3M0uUckntmyTdLWm9pCfzr8GOS8chriTpZtoA3BYR6yRdJ+nC9NxzJXUCFwM3SlpX8O/OJGmxPNjv1J8CPimpg2TM47ulfNDhyjUk3yp3VZlZrStljOP7JLP/rQbK+q0ZEcuB5f3WXVvwfiVJd9NAx25mgIHviNhEcsXWqGqor6OxXh4cN7OaV0pwvBQR/5J5JUeBXIOnjzUzKyU4fiHpC8DtwP78ysJLdGtFsydzMjMrKTjO7vcVIID5I19OdWtpqnNXlZnVvFKuqvK8HKlcg+cdNzMrNnXs4oi4RdJVA22PiK9nV1Z1amlycJiZFWtxHJd+Hf7dc2OEB8fNzIpPHfvN9Ot/H71yqluuqZ6X9h4cfEczszFs0DEOSVOAjwIzC/ePiCXZlVWdcg11bHeLw8xqXClXVd0F/Afwb5R5A+BY4zEOM7PSguOYiPibzCs5CniMw8ystKfj3i3pnZlXchTINdb5BkAzq3mlBMfHgHsk7Zb0gqSdkl7IurBqlHNXlZlZSV1VUzKv4iiRa6hnf1cPPT1BXZ0qXY6ZWUUUuwFwVkQ8BbzuCLvU3LOq8nNy7O/q6X1vZlZrirU4lgKXAzcMsK0mn1VVOCeHg8PMalWxGwAvT7/6WVWpvlkAPc5hZrWrlDEOJJ0GzAZy+XUR8aOsiqpW+XnHfUmumdWyUu4c/wzwTuA0kmlg30VyM2DtBscBB4eZ1a5SLse9BDgX2BoRlwJvAI7JtKoqddy4JgB27jlQ4UrMzCqnlODYGxHdQJekY4FtwMnZllWdpk1Meuq2vrivwpWYmVVOKWMcj0iaBHwPWAW8BDycaVVV6oQJzQBsc3CYWQ0rGhySBHwuInYBN0i6F5gQEWtGpboq09xQz5TxTW5xmFlNKxocERGS7gf+JF3uGJWqqtjUiTm2vbi30mWYmVVMKWMcayWdkXklR4mpE1rc4jCzmlbskSMNEdEFnAGslPRb4I+ASBojZ45SjVVl2sQcq35Xk894NDMDindVPQycCVw4SrUcFaZOzLFrz0H2HvBjR8ysNhXrqhJARPx2oFcpJ5e0QNJGSR2Slg6wfb6kNZK6JC3st22GpPskbZC0XtLMdP070mPWSvo3SaeW/GlHQP6S3G0vubvKzGpTsRZHq6RPHmljRHyl2Ikl1ZM8IPF8oJOku2tZRKwv2G0LcBlw9QCn+AHw+Yi4X9J4ID+D0t8DF0XEBkn/BfhMeo5RMbX3Xo69tE2pyfsgzazGFQuOemA8actjCOYBHRGxCUDSrcBFQG9wRMTmdNsh0+pJmg00RMT96X67CzYHMCF9PxF4boj1Dcm0iS2A7+Uws9pVLDi2RsR1wzj3icAzBcudwFklHvtqYJek24E24F+Bpekd7FcAyyXtJbkZ8U3DqLFsUyf47nEzq22DjnFUSANwDkkX1lzgFPq6o/4auCAipgPfBwbsMpO0RNIqSat27NgxYoW1NNUzaVyjWxxmVrOKBcc7hnnuZ4GTCpanp+tK0QmsjYhN6SXBdwJnSmoF3hARD6X7/Rh4y0AniIibIqI9ItpbW1uH9gmOYOqEnFscZlazjhgcETHcmxVWArMktUlqAhYBy8o4dlIaFADnkYyN7AQmSnp1uv58YMMw6yzbtIk5tr3ku8fNrDaVcuf4kKQthStJ5vDYANwWEeskXSfpQgBJcyV1AhcDN0palx7bTdJN9YCkx0m6zb6dnvMvgJ9KehS4FPivWX2GI5k6scVdVWZWs0qaAXCoImI5sLzfumsL3q8k6cIa6Nj7gdMHWH8HcMfIVlqeaRNz/H73AfZ3ddPc4JsAzay2ZNbiGMvy93I8/+L+CldiZjb6HBxD8Mr0Xo6tfkqumdUgB8cQTPVjR8yshjk4hmCqp5A1sxrm4BiC8c0NHJtr8JVVZlaTHBxDNG1izmMcZlaTHBxD5Hs5zKxWOTiGaJofO2JmNcrBMURTJ+bYsXs/B7t7Bt/ZzGwMcXAM0bSJOSJg+8u+CdDMaouDY4h67+XwALmZ1RgHxxBN67173OMcZlZbHBxD1NficHCYWW1xcAzRhFwD45rq3eIws5rj4BgiSUydmHOLw8xqjoNjGHz3uJnVIgfHMEyd4LvHzaz2ODiGYdrEHM+/vJ/unqh0KWZmo8bBMQzTJuXo7gl2+CZAM6shDo5hmNY7L4fHOcysdjg4hmHqhOQmQI9zmFktcXAMwzTPBGhmNcjBMQyTxjXS3FDnucfNrKY4OIZBEicfP46N216udClmZqPGwTFMc2dOZvXvdvqSXDOrGQ6OYZrXNpnd+7tY/9xLlS7FzGxUODiG6ay24wF46Ok/VLgSM7PRkWlwSFogaaOkDklLB9g+X9IaSV2SFvbbNkPSfZI2SFovaWa6XpI+L+nJdNtVWX6GwUydmOPk48fx0NMvVLIMM7NR05DViSXVAzcA5wOdwEpJyyJifcFuW4DLgKsHOMUPgM9HxP2SxgP5yb0vA04CTouIHkknZPQRSnZW22TuW/88PT1BXZ0qXY6ZWaaybHHMAzoiYlNEHABuBS4q3CEiNkfEY/SFAgCSZgMNEXF/ut/uiNiTbv44cF1E9KTbtmf4GUoyr+14du05yJPbfXWVmY19WQbHicAzBcud6bpSvBrYJel2SY9Iuj5twQC8CrhE0ipJd0uaNdAJJC1J91m1Y8eOIX+IUpzVNhmAh91dZWY1oFoHxxuAc0i6sOYCp5B0UQE0A/sioh34NvC9gU4QETdFRHtEtLe2tmZa7PTjWnjlxJzHOcysJmQZHM+SjEXkTU/XlaITWJt2c3UBdwJnFmy7PX1/B3D6CNQ6LJKY1zaZhza9QITv5zCzsS3L4FgJzJLUJqkJWAQsK+PYSZLyTYXzgPyg+p3Auen7twFPjlC9w3LWKcfz+937efr3f6x0KWZmmcosONKWwpXAvcAG4LaIWCfpOkkXAkiaK6kTuBi4UdK69Nhukm6qByQ9DoikWwrgi8AH0vVfAK7I6jOUY146zuHuKjMb6zK7HBcgIpYDy/utu7bg/UqSLqyBjr2fAbqhImIX8J6RrXT4TplyDFPGN/Pw0y+weN6MSpdjZpaZah0cP+pI4qy2yTy06Q8e5zCzMc3BMYLOOmUyz724j86dnhHQzMYuB8cImuf7OcysBjg4RtCrTziWSeMa/cBDMxvTHBwjqK5OzJ052S0OMxvTHBwj7JxZU9j8hz2s/t3OSpdiZpYJB8cI+8CZ0zluXCP/9xdPVboUM7NMODhG2DHNDVxxzims2LiDxztfrHQ5ZmYjzsGRgUvffDITcg18w60OMxuDHBwZmJBr5LK3tnHf+ufZsNVzkZvZ2OLgyMhH3zqTY5rquWFFR6VLMTMbUQ6OjEwa18Sfv2UmP398Kx3bd1e6HDOzEePgyNAVZ7eRa6jnm251mNkY4uDI0PHjm/nwWTO469Hn2Ox5OsxsjHBwZGzJ/FNobqjjYz9czYt7D1a6HDOzYXNwZOyECTluvPSN/HbHbi7/h5XsPdBd6ZLMzIbFwTEKzpnVytcuOYPVW3by8ZtXc6Crp9IlmZkNmYNjlLzn9Gn87ftez//buIOr//lReno82ZOZHZ0ynTrWDrV43gx27jnAl+/ZSGN9HZ+9cDYTco2VLsvMrCwOjlH28be9in0HuvnGig4efHI717zrNBa+cTp1dap0aWZmJXFX1SiTxCff+RqWfeJsZkwexzU/fYz3ffPXrNnix7Cb2dFBEWO/r729vT1WrVpV6TIOExHctfY5/nb5Bra/vJ/XvXICC143lQV/MpVZrzi20uWZWY2TtDoi2g9b7+CovN37u7j14S3c/cS23gmgXtV6DG89dQqvnTaB06Yey2umHsu4JvcsmtnocXBUcXAUev6lfdy3bhv3rNvG2i27+GN634cE049rYdqEFk6Y0MwrJuQ44dhmJo1r5NhcI8fmGhjfnLyaG+rJNdbR3FBPc2MdDXWivk5IHkcxs9I5OI6S4CjU0xM8u2svG7a+xG+2vUzH9t08/9I+tr+8n20v7mPvwfJuJmysFw11SZBIUF8QKHWCOgmRjMNISVgBiHQ5PU8+gAaMIRVdHNXwckyawXc/MpcZx48b0rFHCg73fVSxujpx0uRxnDR5HO983dRDtkUEu/d38eLeg+ze38XL+7p4ed9B/ri/m/1dPew72Pe1uyfo6u7hYPq1uwd6IujuCXoieUWQvk++kvzX+2/1vU+/DlBv/z9CDttnFP9GidH8x8yqWFPDyF8DlWlwSFoA/B1QD3wnIr7Yb/t84GvA6cCiiPhJwbYZwHeAk0h+5VwQEZsLtn8d+GhEjM/yM1QrSWkXle8DMbPRldnluJLqgRuAdwOzgcWSZvfbbQtwGfCjAU7xA+D6iHgtMA/YXnDuduC4DMo2M7NBZHkfxzygIyI2RcQB4FbgosIdImJzRDwGHPLwpjRgGiLi/nS/3RGxJ91WD1wPXJNh7WZmdgRZBseJwDMFy53pulK8Gtgl6XZJj0i6Pg0MgCuBZRGxdQRrNTOzElXr4HgDcA5wBkl31o+ByyTdDVwMvH2wE0haAiwBmDFjRmaFmpnVmixbHM+SDGznTU/XlaITWJt2c3UBdwJnkgTJqUCHpM3AOEkDzssaETdFRHtEtLe2tg71M5iZWT9ZtjhWArMktZEExiLgQ2UcO0lSa0TsAM4DVkXEz4He61Il7Y6IU0e4bjMzKyKzFkfaUrgSuBfYANwWEeskXSfpQgBJcyV1knQ/3ShpXXpsN3A18ICkx0nu5fp2VrWamVnpfOe4mZkNqKYfOSJpB/C7IR4+Bfj9CJaTNdebLdebvaOt5rFc78kRcdggcU0Ex3BIWjVQ4lYr15st15u9o63mWqzXEzmZmVlZHBxmZlYWB8fgbqp0AWVyvdlyvdk72mquuXo9xmFmZmVxi8PMzMri4ChC0gJJGyV1SFpa6Xr6k/Q9SdslPVGwbrKk+yU9lX6tmsfPSzpJ0gpJ6yWtk/SX6fqqrFlSTtLDkh5N6/0f6fo2SQ+lPxc/ltRU6VoLSapPHw76s3S5auuVtFnS45LWSlqVrqvKnwcASZMk/UTSbyRtkPTmaq1X0mvS72v+9ZKkvxqJeh0cR1DifCKV9g/Agn7rlgIPRMQs4IF0uVp0AX8TEbOBNwGfSL+n1VrzfuC8iHgDMAdYIOlNwJeAr6aPu9kJXF7BGgfylyRPa8ir9nrPjYg5BZeIVuvPAyQT090TEacBbyD5PldlvRGxMf2+zgHeCOwB7mAk6o0IvwZ4AW8G7i1Y/jTw6UrXNUCdM4EnCpY3AtPS99OAjZWusUjtdwHnHw01A+OANcBZJDdPNQz0c1LpF8nDRB8geb7bz0ge11PN9W4GpvRbV5U/D8BE4GnSseFqr7dfje8Efj1S9brFcWTDmU+kkl4RfXOVbANeUclijkTSTJKnHT9EFdecdvusJZmB8n7gt8CuSJ7FBtX3c/E1kknO8pOjHU911xvAfZJWp1MhQPX+PLQBO4Dvp12B35F0DNVbb6FFwC3p+2HX6+AYwyL5k6LqLpuTNB74KfBXEfFS4bZqqzkiuiNp6k8nmdXytAqXdESS/hTYHhGrK11LGc6OiDNJuoQ/IWl+4cYq+3loIJne4e8j4gzgj/Tr5qmyegFIx7QuBP65/7ah1uvgOLLhzCdSSc9LmgaQft0+yP6jSlIjSWjcHBG3p6urumaAiNgFrCDp6pkkKT8lQTX9XLwVuDCdq+ZWku6qv6N66yUink2/bifpf59H9f48dAKdEfFQuvwTkiCp1nrz3g2siYjn0+Vh1+vgOLLe+UTSxF4ELKtwTaVYBnwkff8RknGEqiBJwHeBDRHxlYJNVVmzpFZJk9L3LSTjMRtIAmRhulvV1BsRn46I6RExk+Tn9RcR8WGqtF5Jx0g6Nv+epB/+Car05yEitgHPSHpNuuodwHqqtN4Ci+nrpoKRqLfSgzbV/AIuAJ4k6df+b5WuZ4D6bgG2AgdJ/hq6nKRP+wHgKeBfgcmVrrOg3rNJmsWPAWvT1wXVWjNwOvBIWu8TwLXp+lOAh4EOkuZ/c6VrHaD2twM/q+Z607oeTV/r8v+PVevPQ1rbHGBV+jNxJ3Bcldd7DPAHYGLBumHX6zvHzcysLO6qMjOzsjg4zMysLA4OMzMri4PDzMzK4uAwM7OyODjMzKwsDg4zMyuLg8NsGCT9WTpnx1pJN6YPRVwgaU06j8cD6X6fk/RPkv49nQfhL9L1knS9pCfSeSkuKTj3p9J1j0r6YrruqnQ+k8ck3VqZT221rmHwXcxsIJJeC1wCvDUiDkr6JvBnwP8C5kfE05ImFxxyOsk8JMcAj0j6Ocmzr+aQzO0wBVgp6ZfpuouAsyJiT8F5lgJtEbE//zgUs9Hm4DAbuneQTJCzMnkMFy0k83X8MiKeBoiIFwr2vysi9gJ7Ja0geaDf2cAtEdFN8vC5B4G5wNuA70fEnn7neQy4WdKdJI+8MBt17qoyGzoB/xjpLGsR8Rrgc0X27/98n6E87+c9JDNTnkkSWP7jz0adg8Ns6B4AFko6AZK5sklaBPMltRWsy7tIyTzmx5M8hHAl8CvgknRspBWYT/JAwvuB/yRpXP48kuqAkyJiBfApkhnpxo/C5zQ7hP9aMRuiiFgv6TMkM9jVkTyl+BPAEuD2dN12ksexQxIqK0jGMv5nRDwn6Q6ScY5HSVog10Ty+O57JM0BVkk6ACwHPgv8UNJEktbO1yOZJ8RsVPnpuGajQNLngN0R8b8rXYvZcLmryszMyuIWh5mZlcUtDjMzK4uDw8zMyuLgMDZ8K/UAAAAbSURBVDOzsjg4zMysLA4OMzMri4PDzMzK8v8BPIO63lsh2UcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Plotting the training loss'''\n",
    "plt.plot(train_loss_list)\n",
    "plt.xlabel('ecpocs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Plotting the test loss '''\n",
    "plt.plot(test_loss_list)\n",
    "plt.xlabel('ecpocs')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00638911  0.00754818  0.00012587 -0.00334066 -0.01304236  0.00976687\n",
      "   0.00724119  0.00416717  0.01253169 -0.00703176  0.00167585 -0.00477865\n",
      "  -0.00170698  0.00056628  0.00031129]]\n"
     ]
    }
   ],
   "source": [
    "print(w-clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95224\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def get_pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - get_pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - get_pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic Regression using SGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
